{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations_with_replacement\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import f_regression, r_regression, mutual_info_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Acrobot-v1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11216, 6) (11216,)\n"
     ]
    }
   ],
   "source": [
    "if env_name == 'Pendulum-v1':\n",
    "    agent_name =  'sb_sac'\n",
    "    algo_name= 'maxent'\n",
    "    group_name = 'test_run1'\n",
    "    data_run = 'run_scarlet-glade-713'\n",
    "\n",
    "    dimensions = 3\n",
    "    len_traj = 200\n",
    "\n",
    "    seed = 408      \n",
    "    exp_n = 1\n",
    "\n",
    "    data_exp = f'{env_name}___group_{group_name}/{data_run}'\n",
    "\n",
    "    data_path = f'../../results/{data_exp}/files/'\n",
    "\n",
    "    expert_trajs = np.load(data_path + 'expert_trajs_200.npy')\n",
    "    expert_ts = np.load(data_path + 'expert_ts_200.npy')\n",
    "    expert_rs = np.load(data_path + 'expert_rs_200.npy')\n",
    "\n",
    "    \n",
    "elif env_name == 'CartPole-v1':\n",
    "    agent_name =  'sb_sac'\n",
    "    algo_name= 'maxent'\n",
    "    group_name = 'test_run2'\n",
    "    data_run = 'run_flowing-mountain-300'\n",
    "\n",
    "    dimensions = 4\n",
    "    len_traj = 500\n",
    "    \n",
    "    seed = 408      \n",
    "    exp_n = 1\n",
    "\n",
    "    data_exp = f'{env_name}___group_{group_name}/{data_run}'\n",
    "\n",
    "    data_path = f'../../results/{data_exp}/files/'\n",
    "\n",
    "    expert_trajs = np.load(data_path + 'expert_trajs_200.npy')[:50000]\n",
    "    expert_ts = np.load(data_path + 'expert_ts_200.npy')[:50000]\n",
    "    expert_rs = np.load(data_path + 'expert_rs_200.npy')[:50000]\n",
    "\n",
    "    \n",
    "elif env_name == 'Acrobot-v1':\n",
    "    agent_name =  'sb_sac'\n",
    "    algo_name= 'maxent'\n",
    "    group_name = 'test_run2'\n",
    "    data_run = 'run_splendid-blaze-28'\n",
    "\n",
    "    seed = 408      \n",
    "    exp_n = 1    \n",
    "    \n",
    "    dimensions = 6\n",
    "    len_traj = 500\n",
    "\n",
    "    data_exp = f'{env_name}___group_{group_name}/{data_run}'\n",
    "\n",
    "    data_path = f'../../results/{data_exp}/files/'\n",
    "\n",
    "\n",
    "    expert_trajs = np.load(data_path + 'expert_trajs_100.npy')\n",
    "    expert_ts = np.load(data_path + 'expert_ts_100.npy')\n",
    "    expert_rs = np.load(data_path + 'expert_rs_100.npy')\n",
    "\n",
    "\n",
    "else:\n",
    "    NotImplementedError\n",
    "    \n",
    "    \n",
    "print(expert_trajs.shape, expert_rs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def divide_1d_array_into_chunks(data_array, time_indexes):\n",
    "    \"\"\"\n",
    "    Divide a 1D array into chunks based on sequential time indexes.\n",
    "\n",
    "    Parameters:\n",
    "    - data_array: The 1D array of shape (N,).\n",
    "    - time_indexes: The array representing sequential time indexes for each point.\n",
    "\n",
    "    Returns:\n",
    "    - chunks: A list of chunks, where each chunk is a 1D array.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(time_indexes)):\n",
    "        if time_indexes[i] < time_indexes[i - 1]:\n",
    "            # If the time index resets, create a new chunk\n",
    "            chunks.append(data_array[start_index:i])\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last chunk\n",
    "    chunks.append(data_array[start_index:])\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def divide_into_chunks(data_array, time_indexes):\n",
    "    \"\"\"\n",
    "    Divide a 2D array into chunks based on sequential time indexes.\n",
    "\n",
    "    Parameters:\n",
    "    - data_array: The 2D array of shape (N, d).\n",
    "    - time_indexes: The array representing sequential time indexes for each point.\n",
    "\n",
    "    Returns:\n",
    "    - chunks: A list of chunks, where each chunk is a 2D array.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(time_indexes)):\n",
    "        if time_indexes[i] < time_indexes[i - 1]:\n",
    "            # If the time index resets, create a new chunk\n",
    "            chunks.append(data_array[start_index:i, :])\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last chunk\n",
    "    chunks.append(data_array[start_index:, :])\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Divide into chunks\n",
    "traj_chunks = divide_into_chunks(expert_trajs, expert_ts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "load_data = True\n",
    "normalize = True\n",
    "use_uniform = False\n",
    "run_regression = True\n",
    "max_iter = 10\n",
    "n_trajs = 300\n",
    "num_points = 10000\n",
    "# ratio = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :  [ 5.13107037e-01  5.17043209e-04  1.85796909e-01  1.07996521e-03\n",
      " -2.94198878e-02  7.31103075e-01]\n",
      "std  :  [0.54347388 0.66434708 0.68963981 0.6999109  2.41187855 4.21353822]\n"
     ]
    }
   ],
   "source": [
    "if normalize:\n",
    "    sc = StandardScaler()\n",
    "    expert_trajs_std = sc.fit_transform(expert_trajs)\n",
    "    print('mean : ', sc.mean_)\n",
    "    print('std  : ', sc.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate polynomials of first and second degree\n",
    "var_type=''.join(['c' for _ in range(dimensions)])\n",
    "variables = [f'f_{i}' for i in range(dimensions)]\n",
    "first_degree = variables\n",
    "second_degree = [f\"{x} * {y}\" for x, y in combinations_with_replacement(variables, 2)]\n",
    "\n",
    "# Combine both first and second degree polynomials\n",
    "all_polynomials = first_degree + second_degree\n",
    "\n",
    "# print('\\nFeatures: ', all_polynomials)\n",
    "num_feats = len(all_polynomials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f_0',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'f_3',\n",
       " 'f_4',\n",
       " 'f_5',\n",
       " 'f_0 * f_0',\n",
       " 'f_0 * f_1',\n",
       " 'f_0 * f_2',\n",
       " 'f_0 * f_3',\n",
       " 'f_0 * f_4',\n",
       " 'f_0 * f_5',\n",
       " 'f_1 * f_1',\n",
       " 'f_1 * f_2',\n",
       " 'f_1 * f_3',\n",
       " 'f_1 * f_4',\n",
       " 'f_1 * f_5',\n",
       " 'f_2 * f_2',\n",
       " 'f_2 * f_3',\n",
       " 'f_2 * f_4',\n",
       " 'f_2 * f_5',\n",
       " 'f_3 * f_3',\n",
       " 'f_3 * f_4',\n",
       " 'f_3 * f_5',\n",
       " 'f_4 * f_4',\n",
       " 'f_4 * f_5',\n",
       " 'f_5 * f_5']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_polynomials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 27)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# features\n",
    "feats = np.zeros((num_points, num_feats )) # \n",
    "\n",
    "for idx in range(num_points):\n",
    "\n",
    "    curr_point = expert_trajs_std[idx]\n",
    "    \n",
    "    # find features\n",
    "    second_degree = [x * y for x, y in combinations_with_replacement(curr_point, 2)]\n",
    "\n",
    "    # Combine both first and second degree polynomials\n",
    "    feats[idx, :] = np.array(curr_point.tolist() + second_degree)\n",
    "\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL\n",
    "selected_feats = [i for i in range(len(all_polynomials))]\n",
    "data = feats[:, selected_feats]\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(data)\n",
    "logP_s = kde.score_samples(data[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78,), (96,), (86,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logP_s_chunks = divide_1d_array_into_chunks(logP_s, expert_ts[:num_points])\n",
    "logP_s_chunks[0].shape, logP_s_chunks[1].shape, logP_s_chunks[2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78, 27), (96, 27), (86, 27))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_chunks = divide_into_chunks(feats, expert_ts[:num_points])\n",
    "feat_chunks[0].shape, feat_chunks[1].shape, feat_chunks[2].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct regression problem with density and features\n",
    "$$ log(P(s)) \\propto \\phi(s) $$ \n",
    "\n",
    "#### <center> 1. Linear model: $$ log(P(s)) = \\theta^T  * \\phi(s) $$ </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "logP_s_traj = []\n",
    "X = []\n",
    "for i in range(len(logP_s_chunks)):\n",
    "    \n",
    "    logP_s_traj.append(logP_s_chunks[i].sum())\n",
    "    X.append(feat_chunks[i].sum(axis=0))\n",
    "    \n",
    "\n",
    "logP_s_traj = np.array(logP_s_traj)\n",
    "X = np.array(X)\n",
    "\n",
    "y = logP_s_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 27), (89,))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=0.0, F=f_0            , F-test=0.01, MI=0.15\n",
      "index=1.0, F=f_1            , F-test=0.01, MI=0.05\n",
      "index=2.0, F=f_2            , F-test=0.05, MI=0.20\n",
      "index=3.0, F=f_3            , F-test=0.00, MI=0.00\n",
      "index=4.0, F=f_4            , F-test=0.00, MI=0.09\n",
      "index=5.0, F=f_5            , F-test=0.05, MI=0.24\n",
      "index=6.0, F=f_0 * f_0      , F-test=0.01, MI=0.24\n",
      "index=7.0, F=f_0 * f_1      , F-test=0.00, MI=0.01\n",
      "index=8.0, F=f_0 * f_2      , F-test=0.00, MI=0.13\n",
      "index=9.0, F=f_0 * f_3      , F-test=0.00, MI=0.09\n",
      "index=10.0, F=f_0 * f_4      , F-test=0.00, MI=0.12\n",
      "index=11.0, F=f_0 * f_5      , F-test=0.04, MI=0.15\n",
      "index=12.0, F=f_1 * f_1      , F-test=0.09, MI=0.75\n",
      "index=13.0, F=f_1 * f_2      , F-test=0.00, MI=0.00\n",
      "index=14.0, F=f_1 * f_3      , F-test=0.01, MI=0.30\n",
      "index=15.0, F=f_1 * f_4      , F-test=0.00, MI=0.00\n",
      "index=16.0, F=f_1 * f_5      , F-test=0.01, MI=0.10\n",
      "index=17.0, F=f_2 * f_2      , F-test=0.85, MI=0.83\n",
      "index=18.0, F=f_2 * f_3      , F-test=0.00, MI=0.03\n",
      "index=19.0, F=f_2 * f_4      , F-test=0.02, MI=0.20\n",
      "index=20.0, F=f_2 * f_5      , F-test=0.05, MI=0.18\n",
      "index=21.0, F=f_3 * f_3      , F-test=1.00, MI=1.00\n",
      "index=22.0, F=f_3 * f_4      , F-test=0.00, MI=0.00\n",
      "index=23.0, F=f_3 * f_5      , F-test=0.00, MI=0.00\n",
      "index=24.0, F=f_4 * f_4      , F-test=0.02, MI=0.63\n",
      "index=25.0, F=f_4 * f_5      , F-test=0.01, MI=0.53\n",
      "index=26.0, F=f_5 * f_5      , F-test=0.11, MI=0.53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x9720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import f_regression, r_regression, mutual_info_regression, chi2\n",
    "np.random.seed(0)\n",
    "\n",
    "n = num_feats\n",
    "\n",
    "# Calculate metrics\n",
    "# f_reg = np.abs(r_regression(X, y))\n",
    "# f_reg /= np.max(f_reg)\n",
    "\n",
    "f_test, _ = np.abs(f_regression(X, y))\n",
    "f_test /= np.max(f_test)\n",
    "\n",
    "mi = mutual_info_regression(X, y)\n",
    "mi /= np.max(mi)\n",
    "\n",
    "plt.figure(figsize=(10, int(len(all_polynomials) * 5 )))\n",
    "n = num_feats\n",
    "for i in range(n):\n",
    "    \n",
    "    print(\"index={:.1f}, F={:<{}}, F-test={:.2f}, MI={:.2f}\".format(i, all_polynomials[i], 15, f_test[i], mi[i]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_regression\n",
      "    2 Features: ['f_2 * f_2', 'f_3 * f_3']\n",
      "    3 Features: ['f_2 * f_2', 'f_3 * f_3', 'f_5 * f_5']\n",
      "    4 Features: ['f_1 * f_1', 'f_2 * f_2', 'f_3 * f_3', 'f_5 * f_5']\n",
      "    5 Features: ['f_5', 'f_1 * f_1', 'f_2 * f_2', 'f_3 * f_3', 'f_5 * f_5']\n",
      "    6 Features: ['f_5', 'f_1 * f_1', 'f_2 * f_2', 'f_2 * f_5', 'f_3 * f_3', 'f_5 * f_5']\n",
      "    7 Features: ['f_2', 'f_5', 'f_1 * f_1', 'f_2 * f_2', 'f_2 * f_5', 'f_3 * f_3', 'f_5 * f_5']\n",
      "mutual_info_regression\n",
      "    2 Features: ['f_2 * f_2', 'f_3 * f_3']\n",
      "    3 Features: ['f_1 * f_1', 'f_2 * f_2', 'f_3 * f_3']\n",
      "    4 Features: ['f_1 * f_1', 'f_2 * f_2', 'f_3 * f_3', 'f_4 * f_4']\n",
      "    5 Features: ['f_1 * f_1', 'f_2 * f_2', 'f_3 * f_3', 'f_4 * f_4', 'f_4 * f_5']\n",
      "    6 Features: ['f_1 * f_1', 'f_2 * f_2', 'f_3 * f_3', 'f_4 * f_4', 'f_4 * f_5', 'f_5 * f_5']\n",
      "    7 Features: ['f_1 * f_1', 'f_1 * f_3', 'f_2 * f_2', 'f_3 * f_3', 'f_4 * f_4', 'f_4 * f_5', 'f_5 * f_5']\n"
     ]
    }
   ],
   "source": [
    "# '''\n",
    "# 1. sklearn SelectKBest + f_regression/r_regression\n",
    "\n",
    "# '''\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "\n",
    "print('f_regression')\n",
    "\n",
    "for i in range(2,8):\n",
    "    transformer = SelectKBest(f_regression, k=i).fit(X, y)\n",
    "    #print(f'    BEST {i} features', transformer.get_feature_names_out())\n",
    "    mask = transformer.get_support().astype(int)\n",
    "    selected = [b for a, b in zip(mask, all_polynomials) if a]       \n",
    "    print(f\"    {np.sum(mask)} Features: {selected}\")\n",
    "\n",
    "\n",
    "print('mutual_info_regression')\n",
    "for i in range(2, 8):\n",
    "    transformer = SelectKBest(mutual_info_regression, k=i).fit(X, y)\n",
    "    # print(f'    BEST {i} features', transformer.get_feature_names_out())\n",
    "    mask = transformer.get_support().astype(int)\n",
    "    selected = [b for a, b in zip(mask, all_polynomials) if a]       \n",
    "    print(f\"    {np.sum(mask)} Features: {selected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
